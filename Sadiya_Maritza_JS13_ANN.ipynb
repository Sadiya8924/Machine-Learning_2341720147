{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBJobHUhm8ovDp1XDlavl/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sadiya8924/Machine-Learning_2341720147/blob/main/Sadiya_Maritza_JS13_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Praktikum 1"
      ],
      "metadata": {
        "id": "O9c7G_lS8zpU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNZ3HniJ67dy",
        "outputId": "0c0ab2b0-bda6-4194-b2e8-3a88179c0bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.2655529933008129\n",
            "Epoch 1000, Loss: 0.25019573226036784\n",
            "Epoch 2000, Loss: 0.2497054225357766\n",
            "Epoch 3000, Loss: 0.24809564163930045\n",
            "Epoch 4000, Loss: 0.23006160440788337\n",
            "Epoch 5000, Loss: 0.11644535237074954\n",
            "Epoch 6000, Loss: 0.02488539238070605\n",
            "Epoch 7000, Loss: 0.010854365876961675\n",
            "Epoch 8000, Loss: 0.006581928305737093\n",
            "Epoch 9000, Loss: 0.004631553379062043\n",
            "Prediksi:\n",
            "[[0.06016104]\n",
            " [0.94526047]\n",
            " [0.93102247]\n",
            " [0.05278357]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dataset XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "# Parameter\n",
        "input_size = 2\n",
        "hidden_size = 2\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "\n",
        "# Inisialisasi bobot\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# Fungsi aktivasi\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Training\n",
        "for epoch in range(10000):\n",
        "    # Forward pass\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    # Hitung error\n",
        "    error = y - a2\n",
        "\n",
        "    # Backpropagation\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    # Update bobot\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        loss = np.mean(np.square(error))\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "# Output akhir\n",
        "print(\"Prediksi:\")\n",
        "print(a2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tugas"
      ],
      "metadata": {
        "id": "ez5zd4_19Nxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dataset XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "# --- PERUBAHAN DI SINI ---\n",
        "input_size = 2\n",
        "hidden_size = 3  # Mengubah jumlah neuron hidden layer menjadi 3\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "# -------------------------\n",
        "\n",
        "np.random.seed(42) # Agar perbandingan fair\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "print(\"--- Training dengan 3 Hidden Neurons ---\")\n",
        "for epoch in range(10000):\n",
        "    # Forward pass\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    # Error\n",
        "    error = y - a2\n",
        "\n",
        "    # Backprop\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    # Update\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        loss = np.mean(np.square(error))\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "print(\"Prediksi (3 Hidden Neurons):\")\n",
        "print(a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0991s9tP9EzZ",
        "outputId": "78d09628-011d-4944-8cad-880d7b164cd7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training dengan 3 Hidden Neurons ---\n",
            "Epoch 0, Loss: 0.31824520886068175\n",
            "Epoch 1000, Loss: 0.20569699294249036\n",
            "Epoch 2000, Loss: 0.1418539809567309\n",
            "Epoch 3000, Loss: 0.058651326187686294\n",
            "Epoch 4000, Loss: 0.020112046660991083\n",
            "Epoch 5000, Loss: 0.009992200114726162\n",
            "Epoch 6000, Loss: 0.006269504240552608\n",
            "Epoch 7000, Loss: 0.004460666233485042\n",
            "Epoch 8000, Loss: 0.003421033634262056\n",
            "Epoch 9000, Loss: 0.0027556015957289\n",
            "Prediksi (3 Hidden Neurons):\n",
            "[[0.02515564]\n",
            " [0.95263635]\n",
            " [0.95122343]\n",
            " [0.0627247 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "input_size = 2\n",
        "hidden_size = 3 # Tetap menggunakan 3 neuron sesuai tugas sebelumnya\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "\n",
        "np.random.seed(42)\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# --- DEFINISI FUNGSI BARU ---\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    # Turunan ReLU adalah 1 jika x > 0, dan 0 jika x <= 0\n",
        "    return (x > 0).astype(float)\n",
        "# -----------------------------\n",
        "\n",
        "print(\"\\n--- Training dengan ReLU (Hidden) & Sigmoid (Output) ---\")\n",
        "for epoch in range(10000):\n",
        "    # Forward pass\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = relu(z1)           # MENGGUNAKAN RELU DI HIDDEN LAYER\n",
        "\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)        # TETAP SIGMOID DI OUTPUT\n",
        "\n",
        "    # Error\n",
        "    error = y - a2\n",
        "\n",
        "    # Backpropagation\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    # Backprop ke Hidden Layer (Gunakan turunan ReLU)\n",
        "    d_a1 = np.dot(d_a2, W2.T) * relu_derivative(a1)\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    # Update\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        loss = np.mean(np.square(error))\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "print(\"Prediksi (ReLU):\")\n",
        "print(a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5j9FwRE9FSp",
        "outputId": "a4bdf444-7ebc-452d-8206-1e961d9a49c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training dengan ReLU (Hidden) & Sigmoid (Output) ---\n",
            "Epoch 0, Loss: 0.3274780407035275\n",
            "Epoch 1000, Loss: 0.012797082733424602\n",
            "Epoch 2000, Loss: 0.003283471866346602\n",
            "Epoch 3000, Loss: 0.001730956726043575\n",
            "Epoch 4000, Loss: 0.001146816158135167\n",
            "Epoch 5000, Loss: 0.0008463615651895275\n",
            "Epoch 6000, Loss: 0.0006661559173500909\n",
            "Epoch 7000, Loss: 0.0005467478016979456\n",
            "Epoch 8000, Loss: 0.00046239544032793036\n",
            "Epoch 9000, Loss: 0.0003996816119159116\n",
            "Prediksi (ReLU):\n",
            "[[0.02970009]\n",
            " [0.98605912]\n",
            " [0.98605934]\n",
            " [0.01163533]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Praktikum 2"
      ],
      "metadata": {
        "id": "5GbafX379Ptj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encoding\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Bangun model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Kompilasi\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Latih model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=8)\n",
        "\n",
        "# Evaluasi\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Akurasi: {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYb6poMm9RJ3",
        "outputId": "5402ba3e-601d-455e-a8b0-b2cf40147c79"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3170 - loss: 1.5146\n",
            "Epoch 2/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2851 - loss: 1.2532 \n",
            "Epoch 3/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2883 - loss: 1.1749 \n",
            "Epoch 4/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4017 - loss: 1.1184 \n",
            "Epoch 5/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4008 - loss: 1.1142 \n",
            "Epoch 6/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2843 - loss: 1.1069 \n",
            "Epoch 7/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3553 - loss: 1.0508 \n",
            "Epoch 8/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2739 - loss: 1.0881     \n",
            "Epoch 9/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3436 - loss: 1.0460 \n",
            "Epoch 10/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3720 - loss: 1.0395 \n",
            "Epoch 11/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4535 - loss: 0.9941 \n",
            "Epoch 12/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3055 - loss: 1.0067 \n",
            "Epoch 13/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3237 - loss: 0.9792 \n",
            "Epoch 14/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2983 - loss: 0.9735 \n",
            "Epoch 15/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4778 - loss: 0.9301 \n",
            "Epoch 16/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6982 - loss: 0.9276 \n",
            "Epoch 17/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6888 - loss: 0.9039 \n",
            "Epoch 18/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6918 - loss: 0.8858 \n",
            "Epoch 19/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7285 - loss: 0.8708 \n",
            "Epoch 20/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7276 - loss: 0.8468 \n",
            "Epoch 21/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7231 - loss: 0.8004 \n",
            "Epoch 22/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6934 - loss: 0.7936 \n",
            "Epoch 23/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8127 - loss: 0.7664 \n",
            "Epoch 24/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.7518 \n",
            "Epoch 25/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7640 - loss: 0.7255 \n",
            "Epoch 26/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7823 - loss: 0.7170 \n",
            "Epoch 27/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6988 - loss: 0.6963 \n",
            "Epoch 28/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8449 - loss: 0.6633 \n",
            "Epoch 29/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8309 - loss: 0.6383 \n",
            "Epoch 30/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8670 - loss: 0.6133 \n",
            "Epoch 31/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9302 - loss: 0.6069 \n",
            "Epoch 32/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9209 - loss: 0.6098 \n",
            "Epoch 33/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8828 - loss: 0.5583 \n",
            "Epoch 34/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9069 - loss: 0.5500 \n",
            "Epoch 35/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9811 - loss: 0.5123 \n",
            "Epoch 36/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9683 - loss: 0.5178 \n",
            "Epoch 37/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.4561 \n",
            "Epoch 38/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9460 - loss: 0.4750 \n",
            "Epoch 39/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9604 - loss: 0.4584 \n",
            "Epoch 40/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9549 - loss: 0.4136 \n",
            "Epoch 41/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9476 - loss: 0.4377 \n",
            "Epoch 42/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9762 - loss: 0.4248 \n",
            "Epoch 43/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9684 - loss: 0.3985 \n",
            "Epoch 44/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9775 - loss: 0.3983 \n",
            "Epoch 45/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9815 - loss: 0.4009 \n",
            "Epoch 46/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9781 - loss: 0.3717 \n",
            "Epoch 47/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9749 - loss: 0.3725 \n",
            "Epoch 48/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9325 - loss: 0.3736 \n",
            "Epoch 49/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.3535 \n",
            "Epoch 50/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9769 - loss: 0.2996 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.9333 - loss: 0.3626\n",
            "Akurasi: 0.9333333373069763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tugas"
      ],
      "metadata": {
        "id": "KuwLg9M8-HsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TUGAS 2: Modifikasi Jumlah Neuron ---\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split # Re-import untuk kejelasan blok kode\n",
        "\n",
        "# (Kita gunakan X dan y yang sudah di-encode dari langkah sebelumnya)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Bangun model dengan neuron lebih banyak\n",
        "model_tugas2 = tf.keras.Sequential([\n",
        "    # Mengubah neuron dari 10 menjadi 20\n",
        "    tf.keras.layers.Dense(20, activation='relu', input_shape=(4,)),\n",
        "    # Mengubah neuron dari 8 menjadi 16\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    # Output tetap 3\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model_tugas2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"\\n--- Training Tugas 2 (Neuron Ditambah) ---\")\n",
        "model_tugas2.fit(X_train, y_train, epochs=50, batch_size=8, verbose=0) # verbose=0 agar tidak memenuhi layar\n",
        "\n",
        "loss_2, acc_2 = model_tugas2.evaluate(X_test, y_test)\n",
        "print(f\"Akurasi Model Tugas 2: {acc_2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKL5NJhe9Sma",
        "outputId": "447bf89e-b5ad-4167-cc3e-a09f750fb8dd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Tugas 2 (Neuron Ditambah) ---\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 1.0000 - loss: 0.0635\n",
            "Akurasi Model Tugas 2: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TUGAS 3: Ganti ReLU dengan Sigmoid ---\n",
        "import tensorflow as tf\n",
        "\n",
        "# Bangun model dengan aktivasi Sigmoid di hidden layer\n",
        "model_tugas3 = tf.keras.Sequential([\n",
        "    # Ganti 'relu' dengan 'sigmoid'\n",
        "    tf.keras.layers.Dense(10, activation='sigmoid', input_shape=(4,)),\n",
        "    # Ganti 'relu' dengan 'sigmoid'\n",
        "    tf.keras.layers.Dense(8, activation='sigmoid'),\n",
        "    # Output tetap 'softmax'\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model_tugas3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"\\n--- Training Tugas 3 (Aktivasi Sigmoid) ---\")\n",
        "history = model_tugas3.fit(X_train, y_train, epochs=50, batch_size=8, verbose=0)\n",
        "\n",
        "loss_3, acc_3 = model_tugas3.evaluate(X_test, y_test)\n",
        "print(f\"Akurasi Model Tugas 3 (Sigmoid): {acc_3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUEIhtN4-HK1",
        "outputId": "76cea850-49c3-4da5-e304-5886622f4672"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Tugas 3 (Aktivasi Sigmoid) ---\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - accuracy: 0.7667 - loss: 0.5778\n",
            "Akurasi Model Tugas 3 (Sigmoid): 0.7666666507720947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Praktikum 3"
      ],
      "metadata": {
        "id": "JqeGgaJ3-L2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "# Contoh dataset (buat dummy data)\n",
        "data = pd.DataFrame({\n",
        "    'luas': [50, 60, 70, 80, 90],\n",
        "    'harga': [500, 600, 700, 800, 900]\n",
        "})\n",
        "\n",
        "X = data[['luas']]\n",
        "y = data[['harga']]\n",
        "\n",
        "# Normalisasi\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu', input_shape=(1,)),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(X_train, y_train, epochs=100)\n",
        "\n",
        "# Evaluasi\n",
        "print(\"Prediksi:\", model.predict(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BygY7fX-LIg",
        "outputId": "49060012-c496-4821-c0c4-977ebd88bbde"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.1670\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1633\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1597\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1561\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.1525\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.1490\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.1455\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1421\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1387\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.1354\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.1321\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.1289\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.1257\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.1225\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - loss: 0.1194\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.1163\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.1133\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.1103\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1074\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1045\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1017\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0989\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0962\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0935\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0909\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0883\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0858\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0833\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0809\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0786\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0762\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0740\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0717\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0695\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0674\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0653\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0633\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0613\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0594\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0575\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0557\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0539\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0521\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0504\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0487\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0471\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0455\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0440\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0425\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0411\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0396\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0383\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0369\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0356\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0344\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0332\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0320\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0308\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0297\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0286\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0276\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0266\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0256\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0246\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0237\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0228\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0220\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0211\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0203\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0195\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0188\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0181\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0174\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0167\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0160\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0154\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0148\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0142\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0136\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0131\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0125\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0120\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0115\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0111\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0106\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0102\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0098\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0094\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0090\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0086\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0082\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0079\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0076\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0073\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0070\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0067\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0064\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0061\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0059\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0056\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "Prediksi: [[-1.1170164]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TUGAS 4: Mengubah Learning Rate ---\n",
        "import tensorflow as tf\n",
        "\n",
        "# Menggunakan data X_train dan y_train yang sudah ada dari praktikum sebelumnya\n",
        "\n",
        "# Model struktur sama\n",
        "model_tugas4 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu', input_shape=(1,)),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# --- PERUBAHAN DI SINI ---\n",
        "# Mendefinisikan optimizer dengan Learning Rate khusus (misal 0.1)\n",
        "# Default Adam biasanya 0.001\n",
        "custom_optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "model_tugas4.compile(optimizer=custom_optimizer, loss='mse')\n",
        "\n",
        "print(\"\\n--- Training dengan Learning Rate 0.01 ---\")\n",
        "history = model_tugas4.fit(X_train, y_train, epochs=100, verbose=0) # verbose=0 agar layar tidak penuh\n",
        "\n",
        "# Ambil loss terakhir\n",
        "final_loss = history.history['loss'][-1]\n",
        "print(f\"Loss Akhir (LR=0.01): {final_loss}\")\n",
        "\n",
        "# Bandingkan dengan prediksi\n",
        "print(\"Prediksi Tugas 4:\", model_tugas4.predict(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HVnpinA-7sK",
        "outputId": "da1d0c90-e1a7-4267-a433-f3d191cf4faf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training dengan Learning Rate 0.01 ---\n",
            "Loss Akhir (LR=0.01): 9.393124491907656e-05\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "Prediksi Tugas 4: [[-1.1576257]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP regresi (Keras) - Data Boston\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd # Ditambahkan untuk fix load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --- 1. Load Data (FIXED) ---\n",
        "# Catatan: load_boston dihapus di sklearn versi baru.\n",
        "# Kode di bawah ini adalah pengganti resmi untuk mengambil data yang sama.\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "target = raw_df.values[1::2, 2]\n",
        "\n",
        "X = data\n",
        "y = target\n",
        "# ---------------------------\n",
        "\n",
        "# --- 2. Preprocess ---\n",
        "scaler = StandardScaler()\n",
        "Xs = scaler.fit_transform(X)\n",
        "X_train, X_val, y_train, y_val = train_test_split(Xs, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- 3. Build model ---\n",
        "model = Sequential([\n",
        "    # Menggunakan input_shape dari jumlah kolom X_train\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile dengan learning rate 0.001 (1e-3)\n",
        "model.compile(optimizer=Adam(learning_rate=1e-3), loss='mse', metrics=['mae'])\n",
        "\n",
        "# --- 4. Train ---\n",
        "print(\"Sedang melatih model Boston Housing...\")\n",
        "h = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=32, verbose=0)\n",
        "\n",
        "# --- 5. Plot ---\n",
        "plt.figure(figsize=(10,4))\n",
        "\n",
        "# Grafik MSE (Loss)\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(h.history['loss'], label='train_loss')\n",
        "plt.plot(h.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.title('MSE (Mean Squared Error)')\n",
        "\n",
        "# Grafik MAE (Mean Absolute Error)\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(h.history['mae'], label='train_mae')\n",
        "plt.plot(h.history['val_mae'], label='val_mae')\n",
        "plt.legend()\n",
        "plt.title('MAE (Mean Absolute Error)')\n",
        "\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Evaluasi RMSE\n",
        "from sklearn.metrics import mean_squared_error\n",
        "pred = model.predict(X_val)\n",
        "print('RMSE:', np.sqrt(mean_squared_error(y_val, pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "_nTjzVoN_Ek6",
        "outputId": "57e9e933-d042-4c4e-92cb-a7107a75cc1a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-1701635002.py:12: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sedang melatih model Boston Housing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c913e97a3e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c913e97a3e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "RMSE: 3.3775731955986426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tugas Praktikum"
      ],
      "metadata": {
        "id": "J2AWxOpY_vVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load dataset MNIST\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalisasi data (0-255 → 0-1)\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encoding label\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 2. Bangun model JST\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)), # Ubah gambar 28x28 menjadi vektor 784\n",
        "    Dense(128, activation='relu'),  # Hidden layer 1\n",
        "    Dense(64, activation='relu'),   # Hidden layer 2\n",
        "    Dense(10, activation='softmax') # Output layer (10 kelas)\n",
        "])\n",
        "\n",
        "# 3. Kompilasi model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 4. Latih model\n",
        "print(\"\\n--- Training Model --- \")\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# 5. Evaluasi model\n",
        "print(\"\\n--- Evaluating Model --- \")\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Akurasi pada data uji: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Plbs1HQu_Kyb",
        "outputId": "f4000e02-bca1-496a-e6cd-f7481775c797"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Model --- \n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8752 - loss: 0.4258\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9668 - loss: 0.1091\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.0682\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.0508\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9867 - loss: 0.0404\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0316\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0251\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9937 - loss: 0.0203\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0219\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0141\n",
            "\n",
            "--- Evaluating Model --- \n",
            "Akurasi pada data uji: 0.9773\n"
          ]
        }
      ]
    }
  ]
}